{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73653ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function refine_detections_graph.<locals>.nms_keep_map at 0x7fd7c496c310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function refine_detections_graph.<locals>.nms_keep_map at 0x7fd7c496c310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdo_gamal/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import os\n",
    "import datetime\n",
    "import pixellib\n",
    "from pixellib.instance import instance_segmentation\n",
    "\n",
    "#print(o3d.t.io.RealSenseSensor.list_devices())\n",
    "segment_frame = instance_segmentation(infer_speed = \"fast\")\n",
    "segment_frame.load_model(\"/home/abdo_gamal/gp_ws/src/semantic_segmentation_ros/instance_seg/mask_rcnn_coco.h5\")\n",
    "target_classes = segment_frame.select_target_classes(car =True)\n",
    "\n",
    "\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 15)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 15)\n",
    "pipeline.start(config)\n",
    "align = rs.align(rs.stream.color)\n",
    "\n",
    "to_reset = True\n",
    "# \n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "# \n",
    "pointcloud = o3d.geometry.PointCloud()\n",
    "vis.add_geometry(pointcloud)\n",
    "opt = vis.get_render_option()\n",
    "#opt.background_color = np.asanyarray([0, 0, 0])\n",
    "#opt.point_size = 1\n",
    "opt.show_coordinate_frame = True\n",
    "\n",
    "frames = pipeline.wait_for_frames()\n",
    "frames = pipeline.wait_for_frames()\n",
    "frames = pipeline.wait_for_frames()\n",
    "\n",
    "# \n",
    "while True:\n",
    "    # \n",
    "    frames = pipeline.wait_for_frames()\n",
    "    aligned_frames = align.process(frames)\n",
    "\n",
    "    profile = aligned_frames.get_profile()\n",
    "    # \n",
    "    intrinsics = profile.as_video_stream_profile().get_intrinsics()\n",
    "    pinhole_camera_intrinsic = o3d.camera.PinholeCameraIntrinsic(\\\n",
    "        intrinsics.width, intrinsics.height, intrinsics.fx, \\\n",
    "        intrinsics.fy, intrinsics.ppx, intrinsics.ppy)\n",
    "\n",
    "    color_frame = aligned_frames.get_color_frame()\n",
    "    depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "    spatial = rs.spatial_filter()\n",
    "    #spatial.set_option(rs.option.filter_magnitude, 5)\n",
    "    #spatial.set_option(rs.option.filter_smooth_alpha, 1)\n",
    "    #spatial.set_option(rs.option.filter_smooth_delta, 50)\n",
    "    filtered_depth = spatial.process(depth_frame)\n",
    "\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    depth_image = np.asanyarray(filtered_depth.get_data())\n",
    "    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    " \n",
    "    \"\"\" Prediction \"\"\"\n",
    "   \n",
    "\n",
    "    segmask,color=segment_frame.segmentFrame(color_image,segment_target_classes=target_classes)\n",
    "\n",
    "#segment_target_classes=target_classes\n",
    "#     masked_image=color\n",
    "  #      print( segmask['rois'])\n",
    "        \n",
    "#     print(segmask['masks'].shape)\n",
    "#     masked_img=segmask['masks'][:,:,0]\n",
    "#     for i in range((segmask['masks'].shape[2]-1)):    \n",
    "#         masked_img=np.logical_or(masked_img,segmask['masks'][:,:,i+1])\n",
    "#     masked_img = masked_img.astype(np.uint8) *255\n",
    "    \n",
    "    \n",
    "    \n",
    "    images = np.hstack((color, depth_colormap))\n",
    "    cv2.namedWindow('rgb-d', cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow('rgb-d', images)\n",
    "\n",
    "    # \n",
    "    #color_image = cv2.cvtColor(color, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img_color = o3d.geometry.Image(color)\n",
    "    img_depth = o3d.geometry.Image(depth_image)\n",
    "\n",
    "    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(img_color, img_depth, \\\n",
    "                                                              convert_rgb_to_intensity = False)\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, pinhole_camera_intrinsic)\n",
    "    pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key & 0xFF == ord('s'):\n",
    "        localtime = time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime(time.time()))\n",
    "        pcdfile_path = point_cloud_file + localtime + \".pcd\"\n",
    "        rgb_path = point_cloud_file + localtime + \".jpg\"\n",
    "        depth_path = point_cloud_file + localtime + \".npy\"\n",
    "        print(pcdfile_path)\n",
    "        o3d.io.write_point_cloud(pcdfile_path, pcd)\n",
    "        cv2.imwrite(rgb_path, color_image)\n",
    "        np.save(depth_path, depth_image)\n",
    "\n",
    "    pcd_points = np.asarray(pcd.points).reshape((-1, 3))\n",
    "    pcd_colors = np.asarray(pcd.colors).reshape((-1, 3))\n",
    "    pointcloud.colors = o3d.utility.Vector3dVector(pcd_colors)\n",
    "    pointcloud.points = o3d.utility.Vector3dVector(pcd_points)\n",
    "\n",
    "    # update vis\n",
    "    vis.update_geometry(pointcloud)\n",
    "    if to_reset:\n",
    "        vis.reset_view_point(True)\n",
    "        to_reset = False\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "\n",
    "    if key & 0xFF == ord('q') or key == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyWindow('rgb-d')\n",
    "vis.clear_geometries()\n",
    "vis.destroy_window()\n",
    "pipeline.stop()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198044bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method ProposalLayer.call of <pixellib.instance.mask_rcnn.ProposalLayer object at 0x7fa02cf1adc0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method ProposalLayer.call of <pixellib.instance.mask_rcnn.ProposalLayer object at 0x7fa02cf1adc0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method PyramidROIAlign.call of <pixellib.instance.mask_rcnn.PyramidROIAlign object at 0x7fa02cf2b910>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method PyramidROIAlign.call of <pixellib.instance.mask_rcnn.PyramidROIAlign object at 0x7fa02cf2b910>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method DetectionLayer.call of <pixellib.instance.mask_rcnn.DetectionLayer object at 0x7fa02cd66970>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method DetectionLayer.call of <pixellib.instance.mask_rcnn.DetectionLayer object at 0x7fa02cd66970>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From /home/abdo_gamal/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "WARNING:tensorflow:AutoGraph could not transform <function refine_detections_graph.<locals>.nms_keep_map at 0x7fa02cd1eca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function refine_detections_graph.<locals>.nms_keep_map at 0x7fa02cd1eca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdo_gamal/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(223392, 3)\n",
      "(223392, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284239, 3)\n",
      "(284239, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(282988, 3)\n",
      "(282988, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285487, 3)\n",
      "(285487, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(288228, 3)\n",
      "(288228, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284705, 3)\n",
      "(284705, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286642, 3)\n",
      "(286642, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(282811, 3)\n",
      "(282811, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(282980, 3)\n",
      "(282980, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(283362, 3)\n",
      "(283362, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285131, 3)\n",
      "(285131, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(282508, 3)\n",
      "(282508, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285265, 3)\n",
      "(285265, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(282826, 3)\n",
      "(282826, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(281599, 3)\n",
      "(281599, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(283135, 3)\n",
      "(283135, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(289239, 3)\n",
      "(289239, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284160, 3)\n",
      "(284160, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284379, 3)\n",
      "(284379, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284643, 3)\n",
      "(284643, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285671, 3)\n",
      "(285671, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(282157, 3)\n",
      "(282157, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(283645, 3)\n",
      "(283645, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(283530, 3)\n",
      "(283530, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286968, 3)\n",
      "(286968, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(283583, 3)\n",
      "(283583, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286275, 3)\n",
      "(286275, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285310, 3)\n",
      "(285310, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(288499, 3)\n",
      "(288499, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286903, 3)\n",
      "(286903, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286244, 3)\n",
      "(286244, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286849, 3)\n",
      "(286849, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(287812, 3)\n",
      "(287812, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286026, 3)\n",
      "(286026, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286915, 3)\n",
      "(286915, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(283014, 3)\n",
      "(283014, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(287224, 3)\n",
      "(287224, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284801, 3)\n",
      "(284801, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285104, 3)\n",
      "(285104, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284605, 3)\n",
      "(284605, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(287133, 3)\n",
      "(287133, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285239, 3)\n",
      "(285239, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(287189, 3)\n",
      "(287189, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284541, 3)\n",
      "(284541, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284069, 3)\n",
      "(284069, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284725, 3)\n",
      "(284725, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284982, 3)\n",
      "(284982, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(282104, 3)\n",
      "(282104, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284598, 3)\n",
      "(284598, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285812, 3)\n",
      "(285812, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286967, 3)\n",
      "(286967, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286286, 3)\n",
      "(286286, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285807, 3)\n",
      "(285807, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286448, 3)\n",
      "(286448, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285582, 3)\n",
      "(285582, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286868, 3)\n",
      "(286868, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285138, 3)\n",
      "(285138, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285398, 3)\n",
      "(285398, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284138, 3)\n",
      "(284138, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284969, 3)\n",
      "(284969, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285595, 3)\n",
      "(285595, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286416, 3)\n",
      "(286416, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285681, 3)\n",
      "(285681, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286056, 3)\n",
      "(286056, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286417, 3)\n",
      "(286417, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285543, 3)\n",
      "(285543, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286970, 3)\n",
      "(286970, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(283584, 3)\n",
      "(283584, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(287441, 3)\n",
      "(287441, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286280, 3)\n",
      "(286280, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(283192, 3)\n",
      "(283192, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284600, 3)\n",
      "(284600, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285901, 3)\n",
      "(285901, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(283859, 3)\n",
      "(283859, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285181, 3)\n",
      "(285181, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284828, 3)\n",
      "(284828, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286042, 3)\n",
      "(286042, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(289045, 3)\n",
      "(289045, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(287119, 3)\n",
      "(287119, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(289875, 3)\n",
      "(289875, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285053, 3)\n",
      "(285053, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285860, 3)\n",
      "(285860, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(290188, 3)\n",
      "(290188, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284133, 3)\n",
      "(284133, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(282780, 3)\n",
      "(282780, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(287166, 3)\n",
      "(287166, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286812, 3)\n",
      "(286812, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286931, 3)\n",
      "(286931, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285275, 3)\n",
      "(285275, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285526, 3)\n",
      "(285526, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(288121, 3)\n",
      "(288121, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285912, 3)\n",
      "(285912, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(288294, 3)\n",
      "(288294, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(287012, 3)\n",
      "(287012, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285438, 3)\n",
      "(285438, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285446, 3)\n",
      "(285446, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285384, 3)\n",
      "(285384, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285824, 3)\n",
      "(285824, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284618, 3)\n",
      "(284618, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(283063, 3)\n",
      "(283063, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(287727, 3)\n",
      "(287727, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285832, 3)\n",
      "(285832, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285980, 3)\n",
      "(285980, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(283400, 3)\n",
      "(283400, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285075, 3)\n",
      "(285075, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285747, 3)\n",
      "(285747, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284688, 3)\n",
      "(284688, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286057, 3)\n",
      "(286057, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(287308, 3)\n",
      "(287308, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286163, 3)\n",
      "(286163, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(287688, 3)\n",
      "(287688, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(286687, 3)\n",
      "(286687, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285380, 3)\n",
      "(285380, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(284165, 3)\n",
      "(284165, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(289660, 3)\n",
      "(289660, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(285920, 3)\n",
      "(285920, 3)\n",
      "<class 'open3d.cuda.pybind.utility.Vector3dVector'>\n",
      "(288832, 3)\n",
      "(288832, 3)\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import os\n",
    "import datetime\n",
    "import pixellib\n",
    "from pixellib.instance import instance_segmentation\n",
    "\n",
    "#print(o3d.t.io.RealSenseSensor.list_devices())\n",
    "segment_frame = instance_segmentation(infer_speed = \"fast\")\n",
    "segment_frame.load_model(\"/home/abdo_gamal/gp_ws/src/semantic_segmentation_ros/instance_seg/mask_rcnn_coco.h5\")\n",
    "target_classes = segment_frame.select_target_classes(car =True)\n",
    "\n",
    "\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 15)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 15)\n",
    "pipeline.start(config)\n",
    "align = rs.align(rs.stream.color)\n",
    "\n",
    "to_reset = True\n",
    "# \n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "# \n",
    "pointcloud = o3d.geometry.PointCloud()\n",
    "vis.add_geometry(pointcloud)\n",
    "opt = vis.get_render_option()\n",
    "#opt.background_color = np.asanyarray([0, 0, 0])\n",
    "#opt.point_size = 1\n",
    "opt.show_coordinate_frame = True\n",
    "selected_pcd = o3d.geometry.PointCloud()\n",
    "\n",
    "\n",
    "\n",
    "frames = pipeline.wait_for_frames()\n",
    "frames = pipeline.wait_for_frames()\n",
    "frames = pipeline.wait_for_frames()\n",
    "\n",
    "# \n",
    "while True:\n",
    "    # \n",
    "    frames = pipeline.wait_for_frames()\n",
    "    aligned_frames = align.process(frames)\n",
    "\n",
    "    profile = aligned_frames.get_profile()\n",
    "    # \n",
    "    intrinsics = profile.as_video_stream_profile().get_intrinsics()\n",
    "    pinhole_camera_intrinsic = o3d.camera.PinholeCameraIntrinsic(\\\n",
    "        intrinsics.width, intrinsics.height, intrinsics.fx, \\\n",
    "        intrinsics.fy, intrinsics.ppx, intrinsics.ppy)\n",
    "\n",
    "    color_frame = aligned_frames.get_color_frame()\n",
    "    depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "    spatial = rs.spatial_filter()\n",
    "    #spatial.set_option(rs.option.filter_magnitude, 5)\n",
    "    #spatial.set_option(rs.option.filter_smooth_alpha, 1)\n",
    "    #spatial.set_option(rs.option.filter_smooth_delta, 50)\n",
    "    filtered_depth = spatial.process(depth_frame)\n",
    "\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    depth_image = np.asanyarray(filtered_depth.get_data())\n",
    "    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    " \n",
    "    \"\"\" Prediction \"\"\"\n",
    "   \n",
    "\n",
    "    segmask,color=segment_frame.segmentFrame(color_image)\n",
    "    #segment_target_classes=target_classes\n",
    "    masked_image=color\n",
    "     #  print( segmask['rois'])\n",
    "        \n",
    "  #  print(segmask['masks'].shape)\n",
    "    mask=segmask['masks'][:,:,0]\n",
    "    for i in range((segmask['masks'].shape[2]-1)):    \n",
    "        mask=np.logical_or(mask,segmask['masks'][:,:,i+1])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    images = np.hstack((color, depth_colormap))\n",
    "    cv2.namedWindow('rgb-d', cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow('rgb-d', images)\n",
    "\n",
    "    # \n",
    "    #color_image = cv2.cvtColor(color, cv2.COLOR_BGR2RGB)\n",
    "   # color_masked = color[mask==True]\n",
    "   # depth_image_masked = depth_image[mask==True]\n",
    "    img_color = o3d.geometry.Image(color)\n",
    "    img_depth = o3d.geometry.Image(depth_image)\n",
    "\n",
    "    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(img_color, img_depth, \\\n",
    "                                                              convert_rgb_to_intensity = False)\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, pinhole_camera_intrinsic)\n",
    "    pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "#     selected_pcd.points = o3d.utility.Vector3dVector(selected_points)\n",
    "#     selected_pcd.colors = o3d.utility.Vector3dVector(mask==True)\n",
    "    print(type(pcd.points))\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key & 0xFF == ord('s'):\n",
    "        localtime = time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime(time.time()))\n",
    "        pcdfile_path = point_cloud_file + localtime + \".pcd\"\n",
    "        rgb_path = point_cloud_file + localtime + \".jpg\"\n",
    "        depth_path = point_cloud_file + localtime + \".npy\"\n",
    "      #  print(pcdfile_path)\n",
    "        o3d.io.write_point_cloud(pcdfile_path, pcd)\n",
    "        cv2.imwrite(rgb_path, color_image)\n",
    "        np.save(depth_path, depth_image)\n",
    "\n",
    "    pcd_points = np.asarray(pcd.points).reshape((-1, 3))\n",
    "    pcd_colors = np.asarray(pcd.colors).reshape((-1, 3))\n",
    "    print(pcd_points.shape)\n",
    "    print(pcd_colors.shape)\n",
    "    pointcloud.colors = o3d.utility.Vector3dVector(pcd_colors)\n",
    "    pointcloud.points = o3d.utility.Vector3dVector(pcd_points)\n",
    "\n",
    "    # update vis\n",
    "    vis.update_geometry(pointcloud)\n",
    "    if to_reset:\n",
    "        vis.reset_view_point(True)\n",
    "        to_reset = False\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "\n",
    "    if key & 0xFF == ord('q') or key == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyWindow('rgb-d')\n",
    "vis.clear_geometries()\n",
    "vis.destroy_window()\n",
    "pipeline.stop()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b0abed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
